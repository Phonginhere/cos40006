{
  "id": "UC-001",
  "useCaseType": "Health Monitoring (Wearables, Sensors)",
  "userGroups": [
    "Caregivers and Medical Staff",
    "Older Adults"
  ],
  "pillars": [
    "Pillar 3 - Effective & Personalized Care"
  ],
  "name": "Selective Health Monitoring and Privacy Control",
  "description": "This use case enables Olivia, a privacy-conscious older adult, to receive essential health monitoring through ALFRED while maintaining strict control over data sharing and notifications. Nurse Mike accesses critical health data during work hours with prioritized clinical focus, ensuring efficient, distraction-free patient care.",
  "scenario": "Olivia, a retired social worker in her mid-seventies, lives alone in a quiet suburban neighborhood. She is inherently skeptical of technology and feels overwhelmed by its complexity, especially when it comes to privacy. ALFRED, her new virtual assistant, was installed at her insistence but with strict conditions: no data sharing beyond what she explicitly allows, no unsolicited notifications, and a communication style that is always formal and polite. She rarely wears the health monitoring wearables, fearing that her data might be leaked despite assurances to the contrary.\n\nMike Johnson, a registered nurse working in a bustling urban hospital, is tasked with overseeing Olivia’s health remotely through ALFRED. His priority is clear: he needs accurate, timely clinical data without distractions or emotional information that could slow him down. Mike prefers to access Olivia’s vital signs during his work hours only, with all non-critical notifications silenced. He is aware of Olivia’s privacy concerns but must have access to essential health metrics to provide effective care. This creates an immediate tension, as Mike’s clinical focus clashes with Olivia’s desire to tightly control what data is shared and when.\n\nOne afternoon, Mike logs into ALFRED’s caregiver portal and sees a minimal but prioritized stream of Olivia’s heart rate and blood pressure data, exactly as he requested. However, he notices that some data streams are missing—Olivia had blocked certain sensors from sharing. He respects the boundaries but worries about missing early warning signs. Meanwhile, Olivia, at home, uses voice commands sparingly, activating ALFRED only when necessary with a deliberate “push-to-talk” phrase. She dismisses most notifications, especially those that hint at physical exercises or additional monitoring, finding them intrusive and unnecessary.\n\nMike attempts to schedule a video check-in to assess Olivia’s condition more closely, but Olivia declines, preferring offline communication and feeling uncomfortable with the intrusion. She insists ALFRED keep conversations formal and strictly professional, even when messages from Mike come through. Mike struggles with this formality, feeling it inhibits rapport, but he complies to maintain trust.\n\nIn the end, ALFRED acts as a mediator of this uneasy balance—delivering enough health data to Mike to fulfill his clinical duties while honoring Olivia’s rigid privacy preferences. The system’s design to prioritize clinical information during work hours and suppress non-critical alerts helps Mike stay focused, but the limited data and Olivia’s guarded engagement mean that Mike must rely heavily on scheduled check-ups rather than continuous monitoring. Olivia remains cautious and distant, using ALFRED as a tool rather than a companion, preserving her autonomy and privacy above all else.",
  "personas": [
    "P-004",
    "P-005"
  ]
}